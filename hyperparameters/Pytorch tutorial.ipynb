{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT IS PYTORCH?\n",
    "It’s a Python-based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "    A replacement for NumPy to use the power of GPUs\n",
    "    a deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "#### Getting Started\n",
    "Tensors\n",
    "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "##### NOTE\n",
    "\n",
    "An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0919e-39, 9.2755e-39, 8.4490e-39],\n",
      "        [1.0102e-38, 9.0919e-39, 1.0102e-38],\n",
      "        [8.9082e-39, 8.4489e-39, 9.6429e-39],\n",
      "        [8.4490e-39, 9.6429e-39, 9.2755e-39],\n",
      "        [1.0286e-38, 9.0919e-39, 8.9082e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3994, 0.7288, 0.1531],\n",
      "        [0.7653, 0.5106, 0.2760],\n",
      "        [0.7489, 0.3782, 0.5680],\n",
      "        [0.4331, 0.7091, 0.6725],\n",
      "        [0.4841, 0.8967, 0.9157]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3) ##uniform distribution\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix filled zeros and of dtype long:  (64-bit integer (signed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.1504,  0.1161, -1.6322],\n",
      "        [-2.5082, -0.4457,  0.8398],\n",
      "        [ 1.0572,  1.3848, -0.5259],\n",
      "        [-0.3943,  1.1882,  2.1907],\n",
      "        [ 1.3709,  0.1671,  1.1368]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size:\n",
    "\n",
    "###### Note\n",
    "torch.Size is in fact a tuple, so it supports all tuple operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations\n",
    "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation.\n",
    "\n",
    "Addition: syntax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5737,  0.8664, -1.0770],\n",
      "        [-2.0292,  0.3507,  1.2516],\n",
      "        [ 1.2465,  2.3795, -0.0753],\n",
      "        [-0.0634,  2.0439,  2.5195],\n",
      "        [ 2.0161,  0.4779,  2.0709]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: syntax 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5737,  0.8664, -1.0770],\n",
      "        [-2.0292,  0.3507,  1.2516],\n",
      "        [ 1.2465,  2.3795, -0.0753],\n",
      "        [-0.0634,  2.0439,  2.5195],\n",
      "        [ 2.0161,  0.4779,  2.0709]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: providing an output tensor as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5737,  0.8664, -1.0770],\n",
      "        [-2.0292,  0.3507,  1.2516],\n",
      "        [ 1.2465,  2.3795, -0.0753],\n",
      "        [-0.0634,  2.0439,  2.5195],\n",
      "        [ 2.0161,  0.4779,  2.0709]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5737,  0.8664, -1.0770],\n",
      "        [-2.0292,  0.3507,  1.2516],\n",
      "        [ 1.2465,  2.3795, -0.0753],\n",
      "        [-0.0634,  2.0439,  2.5195],\n",
      "        [ 2.0161,  0.4779,  2.0709]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "Any operation that mutates a tensor in-place is post-fixed with an _. \n",
    "   \n",
    "       For example: x.copy_(y), x.t_(), will change x. (transpose)\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1504,  0.1161, -1.6322],\n",
      "        [-2.5082, -0.4457,  0.8398],\n",
      "        [ 1.0572,  1.3848, -0.5259],\n",
      "        [-0.3943,  1.1882,  2.1907],\n",
      "        [ 1.3709,  0.1671,  1.1368]])\n",
      "tensor([ 0.1161, -0.4457,  1.3848,  1.1882,  0.1671])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing: If you want to resize/reshape tensor, you can use torch.view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a one element tensor, use .item() to get the value as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5922])\n",
      "0.5921700596809387\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Bridge\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other.\n",
    "\n",
    "##### Converting a Torch Tensor to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Converting NumPy Array to Torch Tensor\n",
    "See how changing the np array changed the Torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back. 8-bit integer (signed)\n",
    "\n",
    "#### CUDA Tensors\n",
    "Tensors can be moved onto any device using the .to method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5922], device='cuda:0')\n",
      "tensor([1.5922], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd\n",
    "\n",
    "Autograd is now a core torch package for automatic differentiation. It uses a tape based system for automatic differentiation.\n",
    "\n",
    "In the forward phase, the autograd tape will remember all the operations it executed, and in the backward phase, it will replay the operations.\n",
    "\n",
    "For further detail, see: https://justindomke.wordpress.com/2009/03/24/a-simple-explanation-of-reverse-mode-automatic-differentiation/\n",
    "\n",
    "##### Tensors that track history\n",
    "In autograd, if any input Tensor of an operation has requires_grad=True, the computation will be tracked. After computing the backward pass, a gradient w.r.t. this tensor is accumulated into .grad attribute.\n",
    "\n",
    "There’s one more class which is very important for autograd implementation - a Function. Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each variable has a .grad_fn attribute that references a function that has created a function (except for Tensors created by the user - these have None as .grad_fn).\n",
    "\n",
    "If you want to compute the derivatives, you can call .backward() on a Tensor. If Tensor is a scalar (i.e. it holds a one element tensor), you don’t need to specify any arguments to backward(), however if it has more elements, you need to specify a grad_output argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor and set requires_grad=True to track computation with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.ones(2, 2, requires_grad=False)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)  # we've created x ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do an operation on x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x0000026D37D1D6A0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y was created as the result of an operation, so it has a grad_fn\n",
    "\n",
    "More operations on y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".requires_grad_( ... ) changes an existing Tensor’s requires_grad flag in-place. The input flag defaults to True if not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[-5.3671e-04, -1.3194e+01],\n",
      "        [ 2.0101e+00,  5.5170e+00]])\n",
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x0000026D37D2A780>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "print(a.requires_grad)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a)\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "let's use backprop now and print $ \\frac {\\partial}{\\partial x}out$\n",
    "\n",
    "Let’s backprop now. Because out contains a single scalar, out.backward() is equivalent to out.backward(torch.tensor(1.)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"autograd.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "\n",
    "By default, gradient computation flushes all the internal buffers contained in the graph, so if you even want to do the backward on some part of the graph twice, you need to pass in retain_variables = True during the first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just backprop random gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward(gradient=None, retain_graph=None, create_graph=False)\n",
    "\n",
    "Computes the gradient of current tensor w.r.t. graph leaves.\n",
    "\n",
    "The graph is differentiated using the chain rule. If the tensor is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying gradient. It should be a tensor of matching type and location, that contains the gradient of the differentiated function w.r.t. self.\n",
    "\n",
    "This function accumulates gradients in the leaves - you might need to zero them before calling it.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    gradient (Tensor or None) – Gradient w.r.t. the tensor. If it is a tensor, it will be automatically converted to a Tensor that does not require grad unless create_graph is True. None values can be specified for scalar Tensors or ones that don’t require grad. If a None value would be acceptable then this argument is optional.\n",
    "\n",
    "    retain_graph (bool, optional) – If False, the graph used to compute the grads will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph.\n",
    "\n",
    "    create_graph (bool, optional) – If True, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to False.\n",
    "    \n",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor.backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at an example of vector-Jacobian product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  123.4022,  -163.8910, -1024.1586], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in this case y is no longer a scalar. torch.autograd could not compute the full Jacobian directly, but if we just want the vector-Jacobian product, simply pass the vector to backward as argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stop autograd from tracking history on Tensors with requires_grad=True by wrapping the code block in with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using .detach() to get a new Tensor with the same content but that does not require gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                 train=True,\n",
    "                 transform=torchvision.transforms.ToTensor(),\n",
    "                 download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                 train=False,\n",
    "                 transform=torchvision.transforms.ToTensor(),\n",
    "                 download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d68d8bc88>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d68e29a58>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    '''\n",
    "    Logistic regression, pytorch style\n",
    "    '''\n",
    "    def __init__(self, input_size, out_size):\n",
    "        #super(LogisticRegression, self).__init__()\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.linear = nn.Linear(self.input_size, self.out_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device).view(-1, self.input_size)\n",
    "        x = self.linear(x)          \n",
    "        return x\n",
    "        #return F.log_softmax(x, dim =1)\n",
    "\n",
    "input_size = 28*28 \n",
    "out_size = 10  \n",
    "clf = LogisticRegression(input_size, out_size)\n",
    "clf = clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(clf.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_costs, test_costs= [],[]\n",
    "for epoch in range(epochs+1):\n",
    "    train_loss = 0.0\n",
    "    for X, Y in train_loader:\n",
    "        #Send X and Y to a given device for optimized parameter updates (CUDA or CPU)\n",
    "        output, target = X.to(device), Y.to(device).view(-1)\n",
    "        output = clf(output)\n",
    "        #Compute the loss for the model's prediction and the true value of Y\n",
    "        loss = criterion(output, target)\n",
    "        #Add the train loss value to our train loss accumulator\n",
    "        train_loss += loss.item()\n",
    "        #Initialize gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        #Compute the derivate of the loss w.r.t each parameter via backprop \n",
    "        loss.backward()\n",
    "        #Use the optimizer to update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    #normalize loss by m_train and add to train_costs list\n",
    "    train_costs.append(train_loss / len(train_loader))\n",
    "     \n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in test_loader:\n",
    "            output, target = X.to(device), Y.to(device).view(-1)\n",
    "            #Compute model's guess for X (data) \n",
    "            output = clf(output)                \n",
    "            #Compute loss of X and Y \n",
    "            loss = criterion(output, target)\n",
    "            #Add test loss of current batch to test loss accumulator \n",
    "            test_loss += loss.item()\n",
    "\n",
    "        #normalize loss by m_test and add to test_costs list\n",
    "        test_costs.append(test_loss/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_costs, label ='Train Cost')\n",
    "plt.plot(test_costs, label ='Test Cost')\n",
    "plt.ylabel('Costs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader):\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            x, y = X.to(device), Y.to(device).view(-1)\n",
    "            y_pred = model(x)\n",
    "            _, preds = y_pred.data.max(1)\n",
    "            num_samples += preds.size(0)\n",
    "            num_correct += (y == preds).sum()\n",
    "        \n",
    "    return num_correct.item() / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9041\n",
      "0.9094\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(clf, train_loader))\n",
    "print(get_accuracy(clf, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
